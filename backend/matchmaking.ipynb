{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714ea741-e9cc-4fbb-a9a4-3e8a75789ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: mdr_trials_cleaned.csv\n",
      "Writing to: cdr_trials_cleaned.csv\n",
      "CSV processing complete:\n",
      "- Processed 56 rows\n",
      "- Truncated 43 values that exceeded 255 characters\n",
      "- Output saved to cdr_trials_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def truncate_csv(input_file, output_file, max_length=255):\n",
    "    # Track statistics\n",
    "    truncation_count = 0\n",
    "    processed_rows = 0\n",
    "    \n",
    "    print(f\"Reading from: {input_file}\")\n",
    "    print(f\"Writing to: {output_file}\")\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: Input file '{input_file}' does not exist!\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            \n",
    "            # Get header row (already in lowercase)\n",
    "            header = next(reader)\n",
    "            \n",
    "            with open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "                writer = csv.writer(outfile)\n",
    "                \n",
    "                # Write the header (no changes needed)\n",
    "                writer.writerow(header)\n",
    "                \n",
    "                # Process each row\n",
    "                for row in reader:\n",
    "                    processed_rows += 1\n",
    "                    new_row = []\n",
    "                    \n",
    "                    for value in row:\n",
    "                        if len(value) > max_length:\n",
    "                            truncation_count += 1\n",
    "                            value = value[:max_length-3] + '...'\n",
    "                        new_row.append(value)\n",
    "                    \n",
    "                    writer.writerow(new_row)\n",
    "        \n",
    "        print(f\"CSV processing complete:\")\n",
    "        print(f\"- Processed {processed_rows} rows\")\n",
    "        print(f\"- Truncated {truncation_count} values that exceeded {max_length} characters\")\n",
    "        print(f\"- Output saved to {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV: {e}\")\n",
    "\n",
    "# Use these filenames - paste.txt for input and cdr_trials_cleaned.csv for output\n",
    "input_file = \"mdr_trials_cleaned.csv\"  \n",
    "output_file = \"cdr_trials_cleaned.csv\"  \n",
    "\n",
    "truncate_csv(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ac3fd3-a521-4644-8c97-8d0fd9312dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: mdr_trials_cleaned.csv\n",
      "Writing to: cdr_trials_cleaned.csv\n",
      "CSV processing complete:\n",
      "- Processed 56 rows\n",
      "- Formatted 392 array fields with curly brackets\n",
      "- Removed punctuation from 91 values\n",
      "- Truncated 22 values that exceeded 255 characters\n",
      "- Cleaned 0 values with problematic characters\n",
      "- Output saved to cdr_trials_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import traceback\n",
    "\n",
    "def clean_for_supabase(input_file, output_file, max_length=255):\n",
    "    # Track statistics\n",
    "    truncation_count = 0\n",
    "    cleaning_count = 0\n",
    "    punctuation_count = 0\n",
    "    array_fields_count = 0\n",
    "    processed_rows = 0\n",
    "    \n",
    "    print(f\"Reading from: {input_file}\")\n",
    "    print(f\"Writing to: {output_file}\")\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: Input file '{input_file}' does not exist!\")\n",
    "        return\n",
    "    \n",
    "    # List of columns that should be formatted as arrays\n",
    "    array_columns = [\n",
    "        'organization_type', \n",
    "        'other_leading_organization', \n",
    "        'all_cdr_methods', \n",
    "        'collaborators', \n",
    "        'mrv_provider', \n",
    "        'monitoring_platforms', \n",
    "        'measurements'\n",
    "    ]\n",
    "    \n",
    "    # Create a translation table to remove punctuation except commas for array values\n",
    "    translator = str.maketrans('', '', string.punctuation.replace(',', ''))\n",
    "    \n",
    "    def clean_regular_string(value):\n",
    "        \"\"\"Clean a regular (non-array) string field\"\"\"\n",
    "        if not isinstance(value, str):\n",
    "            return value, False, False, False\n",
    "        \n",
    "        if not value.strip():\n",
    "            return \"\", False, False, False\n",
    "            \n",
    "        cleaned = 0\n",
    "        has_punctuation = False\n",
    "        \n",
    "        # Remove all punctuation\n",
    "        if any(p in value for p in string.punctuation):\n",
    "            original_value = value\n",
    "            value = value.translate(str.maketrans('', '', string.punctuation))\n",
    "            has_punctuation = True\n",
    "        \n",
    "        # Replace control characters and null bytes\n",
    "        value = re.sub(r'[\\x00-\\x1F\\x7F]', '', value)\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        value = re.sub(r'\\s+', ' ', value).strip()\n",
    "        \n",
    "        # Truncate if needed\n",
    "        if len(value) > max_length:\n",
    "            value = value[:max_length-3] + '...'\n",
    "            return value, True, cleaned > 0, has_punctuation\n",
    "            \n",
    "        return value, False, cleaned > 0, has_punctuation\n",
    "    \n",
    "    def clean_array_string(value):\n",
    "        \"\"\"Clean and format an array field with curly brackets and quotes\"\"\"\n",
    "        if not isinstance(value, str):\n",
    "            return \"[]\"\n",
    "        \n",
    "        if not value.strip():\n",
    "            return \"[]\"\n",
    "            \n",
    "        # Split by commas, clean each item\n",
    "        items = [item.strip() for item in value.split(',')]\n",
    "        cleaned_items = []\n",
    "        \n",
    "        for item in items:\n",
    "            if item:  # Skip empty items\n",
    "                # Remove any existing quotes\n",
    "                item = item.replace('\"', '').replace(\"'\", '')\n",
    "                \n",
    "                # Remove punctuation except commas\n",
    "                cleaned_item = item.translate(translator)\n",
    "                \n",
    "                # Normalize whitespace\n",
    "                cleaned_item = re.sub(r'\\s+', ' ', cleaned_item).strip()\n",
    "                \n",
    "                # Truncate if needed\n",
    "                if len(cleaned_item) > max_length:\n",
    "                    cleaned_item = cleaned_item[:max_length-3] + '...'\n",
    "                    nonlocal truncation_count\n",
    "                    truncation_count += 1\n",
    "                \n",
    "                # Only add non-empty items\n",
    "                if cleaned_item:\n",
    "                    cleaned_items.append(f'\"{cleaned_item}\"')\n",
    "        \n",
    "        # Format as Postgres array with curly braces\n",
    "        if not cleaned_items:\n",
    "            return \"[]\"\n",
    "        return \"{\" + \",\".join(cleaned_items) + \"}\"\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            \n",
    "            # Get header row\n",
    "            header = next(reader)\n",
    "            \n",
    "            # Map column names to their indices\n",
    "            column_indices = {name.lower(): i for i, name in enumerate(header)}\n",
    "            \n",
    "            # Find indices of array columns\n",
    "            array_indices = []\n",
    "            for array_col in array_columns:\n",
    "                if array_col in column_indices:\n",
    "                    array_indices.append(column_indices[array_col])\n",
    "                else:\n",
    "                    print(f\"Warning: Array column '{array_col}' not found in header\")\n",
    "            \n",
    "            with open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "                writer = csv.writer(outfile)\n",
    "                \n",
    "                # Write the header\n",
    "                writer.writerow(header)\n",
    "                \n",
    "                # Process each row\n",
    "                for row in reader:\n",
    "                    processed_rows += 1\n",
    "                    new_row = list(row)  # Make a copy we can modify\n",
    "                    \n",
    "                    # Process each cell in the row\n",
    "                    for i in range(len(row)):\n",
    "                        value = row[i]\n",
    "                        if i in array_indices:\n",
    "                            # This is an array field\n",
    "                            new_row[i] = clean_array_string(value)\n",
    "                            array_fields_count += 1\n",
    "                        else:\n",
    "                            # Regular field\n",
    "                            clean_value, was_truncated, was_cleaned, had_punctuation = clean_regular_string(value)\n",
    "                            if was_truncated:\n",
    "                                truncation_count += 1\n",
    "                            if was_cleaned:\n",
    "                                cleaning_count += 1\n",
    "                            if had_punctuation:\n",
    "                                punctuation_count += 1\n",
    "                            new_row[i] = clean_value\n",
    "                    \n",
    "                    writer.writerow(new_row)\n",
    "        \n",
    "        print(f\"CSV processing complete:\")\n",
    "        print(f\"- Processed {processed_rows} rows\")\n",
    "        print(f\"- Formatted {array_fields_count} array fields with curly brackets\")\n",
    "        print(f\"- Removed punctuation from {punctuation_count} values\")\n",
    "        print(f\"- Truncated {truncation_count} values that exceeded {max_length} characters\")\n",
    "        print(f\"- Cleaned {cleaning_count} values with problematic characters\")\n",
    "        print(f\"- Output saved to {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV: {e}\")\n",
    "        print(f\"Exception details: {type(e).__name__}: {str(e)}\")\n",
    "        print(f\"Line number: {sys.exc_info()[2].tb_lineno}\")\n",
    "        try:\n",
    "            print(f\"Full traceback: {traceback.format_exc()}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Use these filenames - adjust as needed\n",
    "input_file = \"mdr_trials_cleaned.csv\"  \n",
    "output_file = \"cdr_trials_cleaned.csv\"  \n",
    "\n",
    "clean_for_supabase(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af0d27c2-34d9-4797-8031-f31a70faf3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: cdr_trials_cleaned.csv\n",
      "Writing to: fixed_cdr_trials.csv\n",
      "Array format fixing complete:\n",
      "- Ensured 305 array fields are properly formatted\n",
      "- Output saved to fixed_cdr_trials.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def fix_postgres_arrays(input_file, output_file):\n",
    "    # Track statistics\n",
    "    fixed_fields = 0\n",
    "    \n",
    "    print(f\"Reading from: {input_file}\")\n",
    "    print(f\"Writing to: {output_file}\")\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            header = next(reader)\n",
    "            \n",
    "            with open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "                writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL)\n",
    "                writer.writerow(header)\n",
    "                \n",
    "                for row in reader:\n",
    "                    new_row = []\n",
    "                    for cell in row:\n",
    "                        # Check if the cell looks like an array (starts with { and ends with })\n",
    "                        if cell.startswith('{\"') and cell.endswith('\"}'):\n",
    "                            # Split by \",\" to get individual array elements\n",
    "                            elements = re.findall(r'\"([^\"]*)\"', cell)\n",
    "                            \n",
    "                            # Reconstruct properly formatted PostgreSQL array\n",
    "                            formatted_array = '{' + ','.join(f'\"{element}\"' for element in elements) + '}'\n",
    "                            \n",
    "                            new_row.append(formatted_array)\n",
    "                            fixed_fields += 1\n",
    "                        else:\n",
    "                            new_row.append(cell)\n",
    "                    \n",
    "                    writer.writerow(new_row)\n",
    "        \n",
    "        print(f\"Array format fixing complete:\")\n",
    "        print(f\"- Ensured {fixed_fields} array fields are properly formatted\")\n",
    "        print(f\"- Output saved to {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV: {e}\")\n",
    "\n",
    "input_file = \"cdr_trials_cleaned.csv\"  \n",
    "output_file = \"fixed_cdr_trials.csv\"  \n",
    "\n",
    "fix_postgres_arrays(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61009c44-078e-4104-9284-eb77bd0f1856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: mdr_trials_cleaned.csv\n",
      "Writing to: mdr_trials_truncated.csv\n",
      "Truncation complete:\n",
      "- Processed 56 rows\n",
      "- Truncated 43 fields to 255 characters or less\n",
      "- Output saved to mdr_trials_truncated.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def truncate_csv_fields(input_file, output_file, max_length=255):\n",
    "    # Track statistics\n",
    "    truncated_fields = 0\n",
    "    processed_rows = 0\n",
    "    \n",
    "    print(f\"Reading from: {input_file}\")\n",
    "    print(f\"Writing to: {output_file}\")\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            header = next(reader)\n",
    "            \n",
    "            with open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "                writer = csv.writer(outfile)\n",
    "                writer.writerow(header)\n",
    "                \n",
    "                for row in reader:\n",
    "                    processed_rows += 1\n",
    "                    new_row = []\n",
    "                    \n",
    "                    for cell in row:\n",
    "                        # Check if the cell exceeds max length\n",
    "                        if len(cell) > max_length:\n",
    "                            # Truncate and add ellipsis\n",
    "                            truncated_cell = cell[:max_length-3] + \"...\"\n",
    "                            new_row.append(truncated_cell)\n",
    "                            truncated_fields += 1\n",
    "                        else:\n",
    "                            new_row.append(cell)\n",
    "                    \n",
    "                    writer.writerow(new_row)\n",
    "        \n",
    "        print(f\"Truncation complete:\")\n",
    "        print(f\"- Processed {processed_rows} rows\")\n",
    "        print(f\"- Truncated {truncated_fields} fields to {max_length} characters or less\")\n",
    "        print(f\"- Output saved to {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV: {e}\")\n",
    "\n",
    "# Use these filenames\n",
    "input_file = \"mdr_trials_cleaned.csv\"\n",
    "output_file = \"mdr_trials_truncated.csv\"\n",
    "\n",
    "truncate_csv_fields(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
